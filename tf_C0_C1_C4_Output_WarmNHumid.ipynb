{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing       \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prerequisits\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(0) \n",
    "tf.config.threading.set_intra_op_parallelism_threads(0)\n",
    "tf.config.set_soft_device_placement(enabled=True)\n",
    "dataframe = pd.read_csv('./Data/SmallOffice_WarmNHumid_Results.csv', delimiter=',')       # load dataset\n",
    "mName = \"SmallOffice_C0_C1_C4_WarmNHumid\"\n",
    "dataset = dataframe.copy()\n",
    "\n",
    "dataset=dataset[['@@WallU@@','@@RoofU@@','@@RoofAbp@@','@@WinU@@','@@WinSHGC@@','@@LPD@@','@@COP@@','c0: Heating', 'c1: Cooling', 'c4: Fans']]\n",
    "#interiorLighting = dataset.drop( 'c2: Interior Lighting', axis='columns', inplace=True)\n",
    "#print(dataset)\n",
    "\n",
    "#exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=7)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "#test_dataset = np.asarray(test_dataset).astype(np.double)\n",
    "\n",
    "train_features = train_dataset[['@@WallU@@','@@RoofU@@','@@RoofAbp@@','@@WinU@@','@@WinSHGC@@','@@LPD@@','@@COP@@']]\n",
    "test_features = test_dataset[['@@WallU@@','@@RoofU@@','@@RoofAbp@@','@@WinU@@','@@WinSHGC@@','@@LPD@@','@@COP@@']]\n",
    "\n",
    "train_labels = train_dataset[['c0: Heating', 'c1: Cooling', 'c4: Fans']]\n",
    "test_labels = test_dataset[['c0: Heating', 'c1: Cooling', 'c4: Fans']]\n",
    "\n",
    "\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_features))\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "    norm,\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3)\n",
    "    ])\n",
    "  model.compile(loss='mean_squared_error',\n",
    "  metrics=['mean_squared_error'],\n",
    "  #metrics=['accuracy'],\n",
    "  optimizer=tf.keras.optimizers.Adam(0.0001))\n",
    "  return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModelToTflite(model_to_save, err, val_loss):\n",
    "  #Making directory for model saving\n",
    "  MODELS_DIR = 'Model_%s'%(mName)\n",
    "  if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "    MODEL_TF = MODELS_DIR + 'Model_{}_Err_{}'.format(mName,round(np.min(err),2))\n",
    "    model_to_save.save(MODEL_TF)\n",
    "    model = keras.models.load_model(MODEL_TF)\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(MODEL_TF+'_model_Val_loss_{}_min_err_{}_mean_err{}_max_err{}.tflite'.format(round(np.min(val_loss),2), round(np.min(err),2), round(np.mean(err),2), round(np.max(err),2)), 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "  else:\n",
    "    MODEL_TF = MODELS_DIR + 'Model_{}_Err_{}'.format(mName,round(np.min(err),2))\n",
    "    model_to_save.save(MODEL_TF)\n",
    "    model = keras.models.load_model(MODEL_TF)\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(MODEL_TF+'_model_Val_loss_{}_min_err_{}_mean_err{}_max_err{}.tflite'.format(round(np.min(val_loss),2), round(np.min(err),2), round(np.mean(err),2), round(np.max(err),2)), 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLoss(loss_type, loss):\n",
    "  MEAN = np.mean(loss)\n",
    "  STD_DEV = np.std(loss)\n",
    "  MIN = np.min(loss)\n",
    "  MAX = np.max(loss)\n",
    "  print(str(loss_type))\n",
    "  print(\"\\t Max: =\", MAX)\n",
    "  print(\"\\t Min: =\", MIN)\n",
    "  print(\"\\t Mean: =\", MEAN)\n",
    "\n",
    "combined_model = build_and_compile_model(normalizer)\n",
    "\n",
    "history = combined_model.fit(\n",
    "    train_features, train_labels,\n",
    "    #validation_split=0.3,\n",
    "    validation_data=(test_features, test_labels),\n",
    "    batch_size=150, shuffle=False,\n",
    "    verbose=1, epochs=100000, use_multiprocessing=True)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "printLoss(\"Training Loss:\", training_loss)\n",
    "printLoss(\"Validation Loss: \", validation_loss)\n",
    "\n",
    "saveModelToTflite(combined_model, training_loss, validation_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 1000])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(history)\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "test_results['combined_model'] = combined_model.evaluate(test_features, test_labels, verbose=1)\n",
    "print (test_results)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "x=train_features.values\n",
    "y_predict= combined_model.predict(x)\n",
    "\n",
    "\n",
    "y_actual=train_labels.values\n",
    " \n",
    "x=0\n",
    "x_Axis = np.linspace(x, x +50 , num=50)\n",
    "plt.style.use('classic')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_Axis, y_predict[:50,0], '-r', label='Predicted')\n",
    "ax.plot(x_Axis, y_actual[:50,0], '--b', label='Actual(from csv)')\n",
    "#ax.axis('equal')\n",
    "ax.legend(loc='upper left', frameon=False)\n",
    "#leg = ax.legend();\n",
    "fig\n",
    "plt.show()\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
